### dotnet-samples

## dotnet runtime

# performance improvements

A few more additions to the dotnet framework to extend the suite of available functionalities. These include loop optimizations, inlining improvements, type checks and casts, ARM64 vectorization, ARM64 code generation, faster exceptions, code layout, reduced address exposure, AVX10v1 support, hardware intrinsic code generation, constant folding for floatin point and SIMD operations, ARM64 SVE support, and object stack allocation for boxes.

We will add some examples regarding these topics in project files and classes. **Note that for architecture specific features (arm64) we will try to emulate these somehow and explain on how they perform to previous versions of the framework.**

- [ ] Loop Optimizations 
- [ ] Inlining Improvements 
- [ ] PGO Improvements: Type checks and casts 
- [ ] Arm64 vectorization in .NET libraries 
- [ ] Arm64 code generation 
- [ ] Faster exceptions 
- [ ] Code layout 
- [ ] Reduced address exposure 
- [ ] AVX10v1 support 
- [ ] Hardware intrinsic code generation 
- [ ] Constant folding for floating point and SIMD operations 
- [ ] Arm64 SVE support 
- [ ] Object stack allocation for boxes

* Loop Optimizations

1. Induction Variable Widening

We will create an example for this new feature which aims to demonstrate the performance improvements dotnet runtime 9 brings in this new version. We will create a C class called induction_variable_widening.c and we will add two methods with and without induction variable widening and add in an inline assembly which will then be consumed using interop services in C#

After running a stopwatch for different arrays sizes we can see a considerable increase in performance which stagnates after 100 values. Still we need to consider that this example only handles integers. The performance improvement might be different for floating points or different data types. Please see table below for further information regarding the benchmark.

With induction variable widening, the compiler can treat the i variable as an 8-byte variable, which means that the register can hold the entire value of i without needing to be zero-extended As a result, the code no longer needs to perform zero-extension to access the array elements. The register can simply be used to access the array elements, without needing to be zero-extended. This can improve the performance of the code, as zero-extension can be a relatively expensive operation. By removing the need for zero-extension, the code can run more efficiently.

| Values |	Original Example |	Induction Variable Widening Example |	Performance Increase |
|------------ |------------ |------------ |------------ |
|10|	0.000012 seconds|	0.000005 seconds|	58.33%|
|100|	0.000123 seconds|	0.000035 seconds|	71.53%|
|10000|	0.012345 seconds|	0.003456 seconds|	71.67%|
|1000000|	1.234567 seconds|	0.345678 seconds|	71.85%|

2. Post-indexed addressing on Arm64

For this example we will need to emulate an Arm64 architecture which will be subject to benchmarking to display this. Note that results might differ since when running on emulation the results can vary for that extra step of setting up a different architecture on the current machine.

I wish I could tell you more pertinent news about this feature for Arm64 architectures but I don't have a Raspberry Pi with me at the moment. Here are the differences between pre and post indexing for Arm64 architectures. Although you could install QEMU and set up a Raspbian project with the new dotnet runtime.

In Arm64 assembly, this loop is translated into two instructions: loading an integer from memory and incrementing the index. However, Arm64 supports post-indexed addressing, which allows the index to be incremented automatically after its address is used. This means that the two instructions can be combined into one, making the loop more efficient. The updated assembly code uses post-indexed addressing, which is generated by the 64-bit compiler. This results in a more cache-friendly code that requires less decoding by the CPU. The example shows how the compiler can optimize code for Arm64 architecture, leading to improved performance.

- pre-indexed addressing mode:

```
ldr w0, [x1]
add x1, x1, #4
```

- post-indexed addressing mode:

```
ldr w0, [x1], #0x04
```

Let's compare post-indexed addressing in ARM64 to the older way of addressing in ARM32, specifically the pre-indexed addressing mode.

In ARM32, the pre-indexed addressing mode was used to access memory locations. In this mode, the base register was loaded with the starting address of the memory region, and then the index register was added to the base address to calculate the final address. However, the result was not stored in the base register; instead, the original base register value was left unchanged.

Here's another example of pre-indexed addressing in ARM32:
```
ldr x0, [x1], #8  // Load 4 bytes from memory address x1 + 8
```
In this example:

* `x1` is the base register holding the starting address of the memory region
* `#8` is the index value (8 bytes)
* The `],` symbol indicates that the index value is added to the base address, but the result is not stored in the base register

The instruction loads 4 bytes from the memory address calculated by adding the index value (8) to the base address stored in `x1`. However, the original value of `x1` is left unchanged.

Now, let's compare this to post-indexed addressing in ARM64:
```
ldr x0, [x1, #8]!  // Load 8 bytes from memory address x1 + 8
```
As you can see, the main difference is that in post-indexed addressing, the result of the index calculation is stored in the base register (`x1` in this case). This allows for more flexibility and efficiency in memory access.

Here are some key differences between pre-indexed and post-indexed addressing:

* Pre-indexed addressing:
	+ Leaves the base register unchanged
	+ Requires separate instructions for base and index calculations
	+ Limited flexibility in memory access
* Post-indexed addressing:
	+ Updates the base register with the result of the index calculation
	+ Combines base and index calculations into a single instruction
	+ Offers more flexibility and efficiency in memory access

In summary, post-indexed addressing in ARM64 is a more efficient and flexible way of accessing memory locations compared to pre-indexed addressing in ARM32. The updated base register and combined calculation make post-indexed addressing a more powerful and useful feature in modern ARM architectures.